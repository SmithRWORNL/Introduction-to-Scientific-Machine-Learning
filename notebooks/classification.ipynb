{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86d95623-541c-4e7a-854f-ca00c0649ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f00b8b24-f555-4b33-973e-304f18efa548",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Get the iris sample dataset\n",
    "iris = datasets.load_iris()\n",
    "\n",
    "# Seperate the dataset into training and test sets\n",
    "train_data, test_data, train_labels, test_labels = train_test_split(iris['data'], iris['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "453031d6-d119-417e-87dc-f675c814b08b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(train_data, test_data):\n",
    "    # Normalize features into [-1, 1] based solely on training data\n",
    "\n",
    "    feature_mins = []\n",
    "    feature_maxs = []\n",
    "    \n",
    "    # Find the extrema of the training features\n",
    "    for i in range(len(train_data[0])):\n",
    "        feature_mins.append(float(train_data[0][i]))\n",
    "        feature_maxs.append(float(train_data[0][i]))\n",
    "    \n",
    "    for point in train_data:\n",
    "        for i in range(len(train_data[0])):\n",
    "            if point[i] < feature_mins[i]:\n",
    "                feature_mins[i] = float(point[i])\n",
    "            elif point[i] > feature_maxs[i]:\n",
    "                feature_maxs[i] = float(point[i])\n",
    "    \n",
    "    # Normalize the training data\n",
    "    normalized_train_data = []\n",
    "    for point in train_data:\n",
    "        new_line = []\n",
    "        for i in range(len(train_data[0])):\n",
    "            new_line.append(((point[i] - feature_mins[i] ) / (feature_maxs[i] - feature_mins[i]) - 0.5) * 2)\n",
    "        normalized_train_data.append(new_line)\n",
    "    \n",
    "    # Normalize the testing data\n",
    "    normalized_test_data = []\n",
    "    for point in test_data:\n",
    "        new_line = []\n",
    "        for i in range(len(train_data[0])):\n",
    "            new_line.append(((point[i] - feature_mins[i] ) / (feature_maxs[i] - feature_mins[i]) - 0.5) * 2)\n",
    "        normalized_test_data.append(new_line)\n",
    "\n",
    "    return normalized_train_data, normalized_test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65333f22-36e6-4da3-9941-f30177bafe96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data that only has the sepal length/width\n",
    "normalized_train_data, normalized_test_data = normalize(train_data, test_data)\n",
    "\n",
    "sepal_train_data = [[i[0], i[1]] for i in normalized_train_data]\n",
    "sepal_test_data = [[i[0], i[1]] for i in normalized_test_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a9cf811-5aaa-4fe1-b744-a25fcb2ef310",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Create a nearest neighbors classifier\n",
    "model = KNeighborsClassifier(3)\n",
    "\n",
    "# Look at only first length/width\n",
    "model.fit(sepal_train_data, train_labels)\n",
    "\n",
    "# Predict the probabilities for each class a single point with sepal width and length slightly larger than any training point\n",
    "print(model.predict_proba([[1.05, 1.05]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8ca5dfb-fa5c-456d-baa1-a233a0625aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "def calculate_scores(model, test_data, test_labels):\n",
    "    # Create a confusion matrix for the test data\n",
    "    confusion_matrix_display = ConfusionMatrixDisplay.from_estimator(\n",
    "        model,\n",
    "        test_data,\n",
    "        test_labels,\n",
    "        cmap=plt.cm.Purples,\n",
    "        display_labels=['setosa', 'versicolor', 'virginica']\n",
    "    )\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    # Calculate the f1 score\n",
    "    print(\"Classwise F1 scores:\")\n",
    "    print(f1_score(model.predict(test_data), test_labels, average=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bc1dc44-b103-45b9-8928-a8a1bdd8e173",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate metrics for our nearest neighbors model\n",
    "calculate_scores(model, sepal_test_data, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13f623db-af66-4bcb-a1a7-82cf5e30c798",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.patches as patches\n",
    "import numpy as np\n",
    "\n",
    "def graph(model, point=None):\n",
    "    # Graph the decision surface of the model, plus a point if given\n",
    "    colors = [[1,0,0],[0,1,0],[0,0,1]]\n",
    "    labels = ['setosa', 'versicolor', 'virginica']\n",
    "\n",
    "    # Graph every point inside the extrema of the training data\n",
    "    xx, yy = np.meshgrid(np.arange(-1, 1, 0.01), np.arange(-1, 1, 0.01))\n",
    "    if hasattr(model, \"predict_proba\"):\n",
    "        Z = model.predict_proba(np.c_[xx.ravel(), yy.ravel()])\n",
    "    else:\n",
    "        Z = model.decision_function(np.c_[xx.ravel(), yy.ravel()])\n",
    "        for line in Z:\n",
    "            sum = 0\n",
    "            for i in line:\n",
    "                if i > 0:\n",
    "                    sum += i\n",
    "            for i in range(len(line)):\n",
    "                if line[i] > 0:\n",
    "                    line[i] = line[i] / sum\n",
    "                else:\n",
    "                    line[i] = 0\n",
    "    Z = Z.reshape((xx.shape[0], xx.shape[1], 3))\n",
    "    im = plt.imshow(Z, extent=(-1, 1, -1, 1), origin=\"lower\")\n",
    "    plt.legend(bbox_to_anchor=(1, 1), handles=[ patches.Patch(color=colors[i], label=labels[i]) for i in range(3) ], loc=2)\n",
    "    if point:\n",
    "        plt.scatter(point[0], point[1], c=point[2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a113414-1323-4b4d-93f6-d3954a6f8e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graph our nearest neighbors model's output\n",
    "graph(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0410c6fe-961b-48cf-ab13-e9e887f7a3ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try with all four features now\n",
    "model.fit(train_data, train_labels)\n",
    "calculate_scores(model, test_data, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4a849fe-c410-4c98-b811-0498fab98b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Train a decision tree classifier\n",
    "model = DecisionTreeClassifier(max_depth=5)\n",
    "model.fit(sepal_train_data, train_labels)\n",
    "\n",
    "calculate_scores(model, sepal_test_data, test_labels)\n",
    "graph(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3afaa4e-d5d8-401f-9958-4e28b5b43278",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrain while allowing a deeper tree\n",
    "model = DecisionTreeClassifier(max_depth=25)\n",
    "model.fit(sepal_train_data, train_labels)\n",
    "\n",
    "calculate_scores(model, sepal_test_data, test_labels)\n",
    "graph(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d6295be-a2c7-4a68-9852-5b716817cc80",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import plot_tree\n",
    "\n",
    "# Show the internals of the tree\n",
    "plot_tree(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40c52035-0f0a-4991-b468-95a9a28be0f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Train an ensemble of 10 trees at once\n",
    "model = RandomForestClassifier(max_depth=5, n_estimators=10)\n",
    "model.fit(sepal_train_data, train_labels)\n",
    "\n",
    "calculate_scores(model, sepal_test_data, test_labels)\n",
    "graph(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f761e5b-8349-4142-a814-028fa9b730bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "# Train an AdaBoost classifier\n",
    "model = AdaBoostClassifier(algorithm=\"SAMME\")\n",
    "model.fit(sepal_train_data, train_labels)\n",
    "\n",
    "calculate_scores(model, sepal_test_data, test_labels)\n",
    "graph(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "178a7df4-73d9-47fd-b032-9edf8e289db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# Train a Naive Bayes classifier with a Gaussian prior\n",
    "model = GaussianNB()\n",
    "model.fit(sepal_train_data, train_labels)\n",
    "\n",
    "calculate_scores(model, sepal_test_data, test_labels)\n",
    "graph(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62d47f4f-46a0-4a43-8ce2-c880172b3454",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# The multinomial distribution assumes nonnegative input, so rescale.\n",
    "positive_sepal_train_data = [[(i[0] + 1) / 2, (i[1] + 1) / 2 ] for i in sepal_train_data]\n",
    "positive_sepal_test_data = [[(i[0] + 1) / 2, (i[1] + 1) / 2 ] for i in sepal_test_data]\n",
    "\n",
    "# Train a Naive Bayes classifier with a multinomial prior\n",
    "model = MultinomialNB()\n",
    "model.fit(positive_sepal_train_data, train_labels)\n",
    "\n",
    "calculate_scores(model, positive_sepal_test_data, test_labels)\n",
    "graph(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d012ff8-b73a-4403-b3f2-71dfe81d2f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import ComplementNB\n",
    "\n",
    "# Train a Naive Bayes classifier with a multinomial prior using the complement of the class for weights\n",
    "model = ComplementNB()\n",
    "model.fit(positive_sepal_train_data, train_labels)\n",
    "\n",
    "calculate_scores(model, positive_sepal_test_data, test_labels)\n",
    "graph(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d36be3f5-d99e-42ed-ba43-e3192010c82a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "# Train a Naive Bayes classifier with a Bernoulli prior\n",
    "model = BernoulliNB()\n",
    "model.fit(sepal_train_data, train_labels)\n",
    "\n",
    "calculate_scores(model, sepal_test_data, test_labels)\n",
    "graph(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c273b42f-33cd-4913-9eb1-5f6da6017d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "# Train a Linear Discriminant Analysis classifier \n",
    "model = LinearDiscriminantAnalysis()\n",
    "model.fit(sepal_train_data, train_labels)\n",
    "\n",
    "calculate_scores(model, sepal_test_data, test_labels)\n",
    "graph(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46cbeb95-5f0b-4b10-8488-4d455f88e664",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "\n",
    "# Train a Quadratic Discriminant Analysis classifier \n",
    "model = QuadraticDiscriminantAnalysis()\n",
    "model.fit(sepal_train_data, train_labels)\n",
    "\n",
    "calculate_scores(model, sepal_test_data, test_labels)\n",
    "graph(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37609019-3365-4462-a001-83c8f370f8f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "# Train a linear Support Vector Machine classifier\n",
    "model = SVC(kernel=\"linear\")\n",
    "model.fit(sepal_train_data, train_labels)\n",
    "\n",
    "calculate_scores(model, sepal_test_data, test_labels)\n",
    "graph(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83b61aca-1fc7-497d-83cf-8d651f537fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a Support Vector Machine classifier using a polynomial kernel function\n",
    "model = SVC(kernel=\"poly\")\n",
    "model.fit(sepal_train_data, train_labels)\n",
    "\n",
    "calculate_scores(model, sepal_test_data, test_labels)\n",
    "graph(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acd783f9-3c3e-4e25-9ea1-46296f83a2b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a Support Vector Machine classifier using a sigmoid kernel function\n",
    "model = SVC(kernel=\"sigmoid\")\n",
    "model.fit(sepal_train_data, train_labels)\n",
    "\n",
    "calculate_scores(model, sepal_test_data, test_labels)\n",
    "graph(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a64d28ec-5046-4460-ab8b-004f65950d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a Support Vector Machine classifier using a radial basis function\n",
    "model = SVC(kernel=\"rbf\")\n",
    "model.fit(sepal_train_data, train_labels)\n",
    "\n",
    "calculate_scores(model, sepal_test_data, test_labels)\n",
    "graph(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67103de4-29cd-4895-b2fe-cd7c4aa1d139",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# Train a multi-layer perceptron classifier\n",
    "model = MLPClassifier(max_iter=1000)\n",
    "model.fit(sepal_train_data, train_labels)\n",
    "\n",
    "calculate_scores(model, sepal_test_data, test_labels)\n",
    "graph(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a68924cf-800a-4a0f-8132-3cd76b81acd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "\n",
    "# Chi squared calculation requires non-negative input\n",
    "positive_train_data = [[(i[0] + 1) / 2, (i[1] + 1) / 2 ] for i in normalized_train_data]\n",
    "\n",
    "#Calculate chi squared values for all features\n",
    "chi2_values = np.concatenate(chi2(positive_train_data, train_labels)).ravel()\n",
    "\n",
    "# Get the two features with the highest chi2 values\n",
    "top_feature_indices = np.argpartition(chi2_values, -2)[-2:]\n",
    "\n",
    "# Get datasets with only the selected features\n",
    "top_feature_train_data = [[i[top_feature_indices[0]], i[top_feature_indices[1]]] for i in normalized_train_data]\n",
    "top_feature_test_data = [[i[top_feature_indices[0]], i[top_feature_indices[1]]] for i in normalized_test_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "624384e0-b5f4-47ee-a5b5-253d234f4488",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Refit the last model using the new features\n",
    "model.fit(top_feature_train_data, train_labels)\n",
    "\n",
    "calculate_scores(model, top_feature_test_data, test_labels)\n",
    "graph(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c043f5ce-9667-47b7-9a10-aa62282a1f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a classifier using all features\n",
    "model = AdaBoostClassifier(algorithm=\"SAMME\")\n",
    "model.fit(normalized_train_data, train_labels)\n",
    "\n",
    "calculate_scores(model, normalized_test_data, test_labels)\n",
    "\n",
    "# Note how internally the model has calculated a numerical score for each feature's contribution to decisions\n",
    "print(\"Feature importances:\")\n",
    "model.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51d336b1-afe3-4abc-a6de-a3fe4ec4c157",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "# Perform recursive feature elimination\n",
    "eliminator = RFE(model, n_features_to_select=2).fit(normalized_train_data, train_labels)\n",
    "\n",
    "# See the list of features to keep\n",
    "print(eliminator.support_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff8540f7-b1a8-458f-81ef-28bee7cbe047",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFECV\n",
    "\n",
    "# Perform recursive feature elimination, using cross validation to calculate the number of features to use\n",
    "eliminator = RFECV(model).fit(normalized_train_data, train_labels)\n",
    "\n",
    "# See the list of features to keep\n",
    "print(eliminator.support_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3f650ea-0891-4b42-a3da-d7c34608819e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Arbitrarily weigh point number 3 as being 100 times more important than all others\n",
    "weights = [1] * len(top_feature_train_data)\n",
    "p=2\n",
    "weights[p] = 100\n",
    "\n",
    "model = SVC(kernel=\"rbf\")\n",
    "model.fit(top_feature_train_data, train_labels, sample_weight=weights)\n",
    "\n",
    "calculate_scores(model, top_feature_test_data, test_labels)\n",
    "graph(model, point=[top_feature_train_data[p][0],top_feature_train_data[p][1],train_labels[p]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ff13a4b-c635-4515-af18-c784d44b0c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate a mistake in data collection/entry setting the first point to extreme positive values\n",
    "top_feature_train_data[0][0] = 2\n",
    "top_feature_train_data[0][1] = 2\n",
    "\n",
    "# Renormalize the data with the incorrect point\n",
    "top_feature_train_data, top_feature_test_data = normalize(top_feature_train_data, top_feature_test_data)\n",
    "\n",
    "# Refit the last model using the new features\n",
    "model.fit(top_feature_train_data, train_labels)\n",
    "\n",
    "calculate_scores(model, top_feature_test_data, test_labels)\n",
    "graph(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "836eddab-7862-4e7c-8502-8a99a29622ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "\n",
    "# Create a local outlier factor model\n",
    "outlier_model = LocalOutlierFactor()\n",
    "outlier_model.fit(top_feature_train_data)\n",
    "\n",
    "# Show all points with unusually low values for clustering\n",
    "print([1 if i < -5 else 0 for i in outlier_model.negative_outlier_factor_])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85eb955b-5d61-4c45-ace8-1c04dd24b8b5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
